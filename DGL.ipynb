{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import register_data_args, load_data\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from pytorch_classification.utils import Bar, AverageMeter\n",
    "%matplotlib inline\n",
    "\n",
    "from models.GCN import Net\n",
    "from torch.utils.data import DataLoader\n",
    "from dataUtils import loadEnergyData, processData, energyDataset\n",
    "from modelUtils import saveCheckpoint, loadCheckpoint, plotPredVsTrue,dotDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = \"data/\"\n",
    "validation_range = [\"2014-10-01 00:00:00\", \"2014-12-31 23:00:00\"]\n",
    "validation_range = [datetime.strptime(date, '%Y-%m-%d %H:%M:%S') for date in validation_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dotDict({      \n",
    "        # model params\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 64,\n",
    "        \"lr\": .001,\n",
    "        \"model_name\": \"DGL_GCN.pth\",\n",
    "        \"steps\":5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGL_EnergyDataset(Dataset):\n",
    "    def __int__(self,args=None,processing_function=None):\n",
    "        self.args = args\n",
    "        self.processing_function=processing_function\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.inputs[index],self.targets[index]\n",
    "    \n",
    "    def process(self,df):\n",
    "        #df = self.processing_function(df)\n",
    "        #print(\"Processed Data\")\n",
    "        grouped = df.groupby('time')\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        for time, group in tqdm(grouped):\n",
    "            group.node = group.node.astype('int64')\n",
    "            group = group.sort_values('node')\n",
    "\n",
    "\n",
    "            node_targets = group.load.values\n",
    "            #print(group.loc[group.time==time,['solar_ecmwf','wind_ecmwf','holiday','hour','dow','month','year',\n",
    "                                          #'season','country','voltage']].values)\n",
    "            node_features = group.loc[group.time==time,['solar_ecmwf','wind_ecmwf','holiday','hour','dow','month','year',\n",
    "                                          'season','country','voltage']].values\n",
    "\n",
    "            node_features = torch.from_numpy(np.array(node_features))\n",
    "            node_targets = torch.from_numpy(np.array(node_targets))\n",
    "           \n",
    "            inputs.append(node_features)\n",
    "            targets.append(node_targets)\n",
    "        #print(torch.stack(inputs).transpose(0,1).shape) \n",
    "        #print(torch.stack(inputs).shape)\n",
    "        self.inputs,self.targets = torch.stack(inputs), \\\n",
    "        torch.stack(targets)\n",
    "        self.inputs = self.inputs.type(torch.FloatTensor)\n",
    "        self.targets = self.targets.type(torch.FloatTensor)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasets(energy_demand, validation_range):\n",
    "    energy_demand['time'] = pd.to_datetime(energy_demand['time'], format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # extract validation and training sets\n",
    "    train_df = energy_demand[energy_demand['time'] < validation_range[0]].reset_index(drop = True)\n",
    "    val_df = energy_demand[(energy_demand['time'] >= validation_range[0]) & \n",
    "                           (energy_demand['time'] <= validation_range[1])].reset_index(drop = True)\n",
    "    \n",
    "    train_dataset = DGL_EnergyDataset()\n",
    "    valid_dataset = DGL_EnergyDataset()\n",
    "    train_dataset.process(train_df)\n",
    "    valid_dataset.process(val_df)\n",
    "    #print(valid_dataset)\n",
    "    #train_dataset = train_dataset.type(torch.FloatTensor)\n",
    "    #valid_dataset = valid_dataset.type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "    return train_dataset,valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "energy_demand, adj_mat = loadEnergyData(processed_dir, incl_nodes = 300, partial = False)\n",
    "#bacis preprocessing and normalization\n",
    "energy_demand = processData(energy_demand)\n",
    "#train_dataset,val_dataset = getDatasets(energy_demand)\n",
    "#train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>time</th>\n",
       "      <th>solar_ecmwf</th>\n",
       "      <th>wind_ecmwf</th>\n",
       "      <th>holiday</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "      <th>country</th>\n",
       "      <th>voltage</th>\n",
       "      <th>load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7891195</td>\n",
       "      <td>300</td>\n",
       "      <td>2014-12-31 19:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2457</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7891196</td>\n",
       "      <td>300</td>\n",
       "      <td>2014-12-31 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7891197</td>\n",
       "      <td>300</td>\n",
       "      <td>2014-12-31 21:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2924</td>\n",
       "      <td>0</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7891198</td>\n",
       "      <td>300</td>\n",
       "      <td>2014-12-31 22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7891199</td>\n",
       "      <td>300</td>\n",
       "      <td>2014-12-31 23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3023</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7891200 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         node                 time  solar_ecmwf  wind_ecmwf  holiday  \\\n",
       "0           1  2012-01-01 00:00:00          0.0      0.0284        1   \n",
       "1           1  2012-01-01 01:00:00          0.0      0.0336        1   \n",
       "2           1  2012-01-01 02:00:00          0.0      0.0392        1   \n",
       "3           1  2012-01-01 03:00:00          0.0      0.0424        1   \n",
       "4           1  2012-01-01 04:00:00          0.0      0.0475        1   \n",
       "...       ...                  ...          ...         ...      ...   \n",
       "7891195   300  2014-12-31 19:00:00          0.0      0.2457        0   \n",
       "7891196   300  2014-12-31 20:00:00          0.0      0.2605        0   \n",
       "7891197   300  2014-12-31 21:00:00          0.0      0.2924        0   \n",
       "7891198   300  2014-12-31 22:00:00          0.0      0.2836        0   \n",
       "7891199   300  2014-12-31 23:00:00          0.0      0.3023        0   \n",
       "\n",
       "             hour       dow  month  year  season  country  voltage      load  \n",
       "0        0.000000  1.000000    0.0   0.0     1.0      1.0      0.0  0.007619  \n",
       "1        0.043478  1.000000    0.0   0.0     1.0      1.0      0.0  0.007149  \n",
       "2        0.086957  1.000000    0.0   0.0     1.0      1.0      0.0  0.006711  \n",
       "3        0.130435  1.000000    0.0   0.0     1.0      1.0      0.0  0.006343  \n",
       "4        0.173913  1.000000    0.0   0.0     1.0      1.0      0.0  0.006150  \n",
       "...           ...       ...    ...   ...     ...      ...      ...       ...  \n",
       "7891195  0.826087  0.333333    1.0   1.0     1.0      0.5      0.0  0.013321  \n",
       "7891196  0.869565  0.333333    1.0   1.0     1.0      0.5      0.0  0.012708  \n",
       "7891197  0.913043  0.333333    1.0   1.0     1.0      0.5      0.0  0.012363  \n",
       "7891198  0.956522  0.333333    1.0   1.0     1.0      0.5      0.0  0.013236  \n",
       "7891199  1.000000  0.333333    1.0   1.0     1.0      0.5      0.0  0.013377  \n",
       "\n",
       "[7891200 rows x 13 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24096 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "100%|██████████| 24096/24096 [01:21<00:00, 294.59it/s]\n",
      "100%|██████████| 2208/2208 [00:07<00:00, 302.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset,val_dataset = getDatasets(energy_demand,validation_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "num_of_nodes = train_dataset.inputs.shape[1]\n",
    "print(num_of_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fromNode</th>\n",
       "      <th>toNode</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>numLines</th>\n",
       "      <th>limit</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>559</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>83.125520</td>\n",
       "      <td>1</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>51.227041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>561</td>\n",
       "      <td>0.015980</td>\n",
       "      <td>62.578223</td>\n",
       "      <td>1</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>34.002397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>344</td>\n",
       "      <td>336</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>75.687824</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.467094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>344</td>\n",
       "      <td>566</td>\n",
       "      <td>0.013770</td>\n",
       "      <td>72.621641</td>\n",
       "      <td>1</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>34.755553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>344</td>\n",
       "      <td>356</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>47.348485</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.628358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2151</td>\n",
       "      <td>1364</td>\n",
       "      <td>1360</td>\n",
       "      <td>0.073660</td>\n",
       "      <td>13.575889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.246338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2152</td>\n",
       "      <td>1362</td>\n",
       "      <td>1363</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>208.116545</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.461581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2153</td>\n",
       "      <td>1362</td>\n",
       "      <td>1368</td>\n",
       "      <td>0.076860</td>\n",
       "      <td>13.010669</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.718657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2154</td>\n",
       "      <td>1362</td>\n",
       "      <td>1361</td>\n",
       "      <td>0.009610</td>\n",
       "      <td>104.058273</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.198719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2155</td>\n",
       "      <td>1368</td>\n",
       "      <td>1369</td>\n",
       "      <td>0.118490</td>\n",
       "      <td>8.439531</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.647831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2156 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fromNode  toNode         X           Y  numLines   limit     length\n",
       "0          344     559  0.012030   83.125520         1  1260.0  51.227041\n",
       "1          344     561  0.015980   62.578223         1  1490.0  34.002397\n",
       "2          344     336  0.013212   75.687824         2     0.0  25.467094\n",
       "3          344     566  0.013770   72.621641         1  1320.0  34.755553\n",
       "4          344     356  0.021120   47.348485         1     0.0  61.628358\n",
       "...        ...     ...       ...         ...       ...     ...        ...\n",
       "2151      1364    1360  0.073660   13.575889         1     0.0  63.246338\n",
       "2152      1362    1363  0.004805  208.116545         2     0.0   9.461581\n",
       "2153      1362    1368  0.076860   13.010669         1     0.0  51.718657\n",
       "2154      1362    1361  0.009610  104.058273         1     0.0  15.198719\n",
       "2155      1368    1369  0.118490    8.439531         1     0.0  62.647831\n",
       "\n",
       "[2156 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df = pd.read_csv(processed_dir+'network_edges.csv')\n",
    "#just try partial data\n",
    "#edge_df = edge_df[edge_df.fromNode<20]\n",
    "# edge_df = edge_df[edge_df.toNode <20]\n",
    "edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = DGLGraph()\n",
    "#g.add_nodes(num_of_nodes)\n",
    "#g.add_edges(edge_df.fromNode-1,edge_df.toNode-1)\n",
    "def build_energy_demand_graph(df,edge_df):\n",
    "    node = list(list(map(int,set(df[\"node\"]))))\n",
    "    edge_df = edge_df[edge_df.fromNode.isin(node)& edge_df.toNode.isin(node)]\n",
    "    g = DGLGraph()\n",
    "    g.add_nodes(max(node))\n",
    "    src = tuple(edge_df[\"fromNode\"]-1)\n",
    "    dst = tuple(edge_df[\"toNode\"]-1)\n",
    "    g.add_edges(src,dst)\n",
    "    return(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=build_energy_demand_graph(energy_demand,edge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_msg = fn.copy_src(src='h', out='m')\n",
    "gcn_reduce = fn.sum(msg='m', out='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (gcn1): GCN(\n",
      "    (apply_mod): NodeApplyModule(\n",
      "      (linear): Linear(in_features=10, out_features=16, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (gcn2): GCN(\n",
      "    (apply_mod): NodeApplyModule(\n",
      "      (linear): Linear(in_features=16, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 1\n",
      "Saving Checkpoint...\n",
      "Current Training Loss: 0.00200603\n",
      "Current Validation Loss: 0.00204683\n",
      "\n",
      "\n",
      "Epoch Number: 2\n",
      "Saving Checkpoint...\n",
      "Current Training Loss: 0.0020066\n",
      "Current Validation Loss: 0.00204421\n",
      "\n",
      "\n",
      "Epoch Number: 3\n",
      "Current Training Loss: 0.0020058\n",
      "Current Validation Loss: 0.00204723\n",
      "\n",
      "\n",
      "Epoch Number: 4\n",
      "Current Training Loss: 0.00200641\n",
      "Current Validation Loss: 0.00207173\n",
      "\n",
      "\n",
      "Epoch Number: 5\n",
      "Current Training Loss: 0.00200654\n",
      "Current Validation Loss: 0.00204467\n",
      "\n",
      "\n",
      "Epoch Number: 6\n",
      "Current Training Loss: 0.00200088\n",
      "Current Validation Loss: 0.0020555\n",
      "\n",
      "\n",
      "Epoch Number: 7\n",
      "Current Training Loss: 0.00200071\n",
      "Current Validation Loss: 0.00204427\n",
      "\n",
      "\n",
      "Epoch Number: 8\n",
      "Current Training Loss: 0.00200095\n",
      "Current Validation Loss: 0.00206697\n",
      "\n",
      "\n",
      "Epoch Number: 9\n",
      "Current Training Loss: 0.00200066\n",
      "Current Validation Loss: 0.0020503\n",
      "\n",
      "\n",
      "Epoch Number: 10\n",
      "Current Training Loss: 0.0020009\n",
      "Current Validation Loss: 0.00204704\n",
      "\n",
      "\n",
      "Epoch Number: 11\n",
      "Current Training Loss: 0.00199804\n",
      "Current Validation Loss: 0.00204778\n",
      "\n",
      "\n",
      "Epoch Number: 12\n",
      "Current Training Loss: 0.00199789\n",
      "Current Validation Loss: 0.0020551\n",
      "\n",
      "\n",
      "Epoch Number: 13\n",
      "Current Training Loss: 0.00199788\n",
      "Current Validation Loss: 0.00204698\n",
      "\n",
      "\n",
      "Epoch Number: 14\n",
      "Current Training Loss: 0.0019981\n",
      "Current Validation Loss: 0.00204431\n",
      "\n",
      "\n",
      "Epoch Number: 15\n",
      "Current Training Loss: 0.0019979\n",
      "Current Validation Loss: 0.00204492\n",
      "\n",
      "\n",
      "Epoch Number: 16\n",
      "Current Training Loss: 0.00199622\n",
      "Current Validation Loss: 0.00204424\n",
      "\n",
      "\n",
      "Epoch Number: 17\n",
      "Current Training Loss: 0.00199629\n",
      "Current Validation Loss: 0.00204435\n",
      "\n",
      "\n",
      "Epoch Number: 18\n",
      "Saving Checkpoint...\n",
      "Current Training Loss: 0.00199626\n",
      "Current Validation Loss: 0.00204402\n",
      "\n",
      "\n",
      "Epoch Number: 19\n",
      "Current Training Loss: 0.00199628\n",
      "Current Validation Loss: 0.00204768\n",
      "\n",
      "\n",
      "Epoch Number: 20\n",
      "Current Training Loss: 0.00199625\n",
      "Current Validation Loss: 0.00204518\n",
      "\n",
      "\n",
      "Epoch Number: 21\n",
      "Saving Checkpoint...\n",
      "Current Training Loss: 0.00199455\n",
      "Current Validation Loss: 0.0020436\n",
      "\n",
      "\n",
      "Epoch Number: 22\n",
      "Current Training Loss: 0.00199386\n",
      "Current Validation Loss: 0.00204526\n",
      "\n",
      "\n",
      "Epoch Number: 23\n",
      "Current Training Loss: 0.00199387\n",
      "Current Validation Loss: 0.00204377\n",
      "\n",
      "\n",
      "Epoch Number: 24\n",
      "Current Training Loss: 0.00199384\n",
      "Current Validation Loss: 0.00204431\n",
      "\n",
      "\n",
      "Epoch Number: 25\n",
      "Current Training Loss: 0.00199384\n",
      "Current Validation Loss: 0.00204472\n",
      "\n",
      "\n",
      "Epoch Number: 26\n",
      "Saving Checkpoint...\n",
      "Current Training Loss: 0.0019932\n",
      "Current Validation Loss: 0.00204345\n",
      "\n",
      "\n",
      "Epoch Number: 27\n",
      "Current Training Loss: 0.00199315\n",
      "Current Validation Loss: 0.00204435\n",
      "\n",
      "\n",
      "Epoch Number: 28\n",
      "Current Training Loss: 0.00199319\n",
      "Current Validation Loss: 0.00204384\n",
      "\n",
      "\n",
      "Epoch Number: 29\n",
      "Current Training Loss: 0.0019932\n",
      "Current Validation Loss: 0.00204422\n",
      "\n",
      "\n",
      "Epoch Number: 30\n",
      "Current Training Loss: 0.00199318\n",
      "Current Validation Loss: 0.0020435\n",
      "\n",
      "\n",
      "Epoch Number: 31\n",
      "Current Training Loss: 0.00199286\n",
      "Current Validation Loss: 0.00204402\n",
      "\n",
      "\n",
      "Epoch Number: 32\n",
      "Current Training Loss: 0.00199284\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 33\n",
      "Current Training Loss: 0.00199285\n",
      "Current Validation Loss: 0.00204446\n",
      "\n",
      "\n",
      "Epoch Number: 34\n",
      "Current Training Loss: 0.00199285\n",
      "Current Validation Loss: 0.00204397\n",
      "\n",
      "\n",
      "Epoch Number: 35\n",
      "Current Training Loss: 0.00199286\n",
      "Current Validation Loss: 0.00204584\n",
      "\n",
      "\n",
      "Epoch Number: 36\n",
      "Current Training Loss: 0.00199266\n",
      "Current Validation Loss: 0.00204347\n",
      "\n",
      "\n",
      "Epoch Number: 37\n",
      "Current Training Loss: 0.00199266\n",
      "Current Validation Loss: 0.0020442\n",
      "\n",
      "\n",
      "Epoch Number: 38\n",
      "Current Training Loss: 0.00199266\n",
      "Current Validation Loss: 0.00204346\n",
      "\n",
      "\n",
      "Epoch Number: 39\n",
      "Current Training Loss: 0.00199267\n",
      "Current Validation Loss: 0.00204423\n",
      "\n",
      "\n",
      "Epoch Number: 40\n",
      "Current Training Loss: 0.00199266\n",
      "Current Validation Loss: 0.00204427\n",
      "\n",
      "\n",
      "Epoch Number: 41\n",
      "Current Training Loss: 0.00199256\n",
      "Current Validation Loss: 0.00204445\n",
      "\n",
      "\n",
      "Epoch Number: 42\n",
      "Current Training Loss: 0.00199256\n",
      "Current Validation Loss: 0.00204391\n",
      "\n",
      "\n",
      "Epoch Number: 43\n",
      "Current Training Loss: 0.00199257\n",
      "Current Validation Loss: 0.00204399\n",
      "\n",
      "\n",
      "Epoch Number: 44\n",
      "Current Training Loss: 0.00199257\n",
      "Current Validation Loss: 0.00204448\n",
      "\n",
      "\n",
      "Epoch Number: 45\n",
      "Current Training Loss: 0.00199256\n",
      "Current Validation Loss: 0.00204427\n",
      "\n",
      "\n",
      "Epoch Number: 46\n",
      "Current Training Loss: 0.00199252\n",
      "Current Validation Loss: 0.00204396\n",
      "\n",
      "\n",
      "Epoch Number: 47\n",
      "Current Training Loss: 0.00199252\n",
      "Current Validation Loss: 0.00204396\n",
      "\n",
      "\n",
      "Epoch Number: 48\n",
      "Current Training Loss: 0.00199252\n",
      "Current Validation Loss: 0.0020439\n",
      "\n",
      "\n",
      "Epoch Number: 49\n",
      "Current Training Loss: 0.00199252\n",
      "Current Validation Loss: 0.00204364\n",
      "\n",
      "\n",
      "Epoch Number: 50\n",
      "Current Training Loss: 0.00199253\n",
      "Current Validation Loss: 0.00204389\n",
      "\n",
      "\n",
      "Epoch Number: 51\n",
      "Current Training Loss: 0.0019925\n",
      "Current Validation Loss: 0.00204389\n",
      "\n",
      "\n",
      "Epoch Number: 52\n",
      "Current Training Loss: 0.0019925\n",
      "Current Validation Loss: 0.00204411\n",
      "\n",
      "\n",
      "Epoch Number: 53\n",
      "Current Training Loss: 0.0019925\n",
      "Current Validation Loss: 0.00204384\n",
      "\n",
      "\n",
      "Epoch Number: 54\n",
      "Current Training Loss: 0.0019925\n",
      "Current Validation Loss: 0.00204384\n",
      "\n",
      "\n",
      "Epoch Number: 55\n",
      "Current Training Loss: 0.00199251\n",
      "Current Validation Loss: 0.00204382\n",
      "\n",
      "\n",
      "Epoch Number: 56\n",
      "Current Training Loss: 0.00199249\n",
      "Current Validation Loss: 0.00204402\n",
      "\n",
      "\n",
      "Epoch Number: 57\n",
      "Current Training Loss: 0.00199249\n",
      "Current Validation Loss: 0.00204378\n",
      "\n",
      "\n",
      "Epoch Number: 58\n",
      "Current Training Loss: 0.00199249\n",
      "Current Validation Loss: 0.002044\n",
      "\n",
      "\n",
      "Epoch Number: 59\n",
      "Current Training Loss: 0.00199249\n",
      "Current Validation Loss: 0.00204402\n",
      "\n",
      "\n",
      "Epoch Number: 60\n",
      "Current Training Loss: 0.00199249\n",
      "Current Validation Loss: 0.00204422\n",
      "\n",
      "\n",
      "Epoch Number: 61\n",
      "Current Training Loss: 0.00199249\n",
      "Current Validation Loss: 0.00204403\n",
      "\n",
      "\n",
      "Epoch Number: 62\n",
      "Current Training Loss: 0.00199249\n",
      "Current Validation Loss: 0.00204397\n",
      "\n",
      "\n",
      "Epoch Number: 63\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204399\n",
      "\n",
      "\n",
      "Epoch Number: 64\n",
      "Current Training Loss: 0.00199249\n",
      "Current Validation Loss: 0.00204399\n",
      "\n",
      "\n",
      "Epoch Number: 65\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204391\n",
      "\n",
      "\n",
      "Epoch Number: 66\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204388\n",
      "\n",
      "\n",
      "Epoch Number: 67\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204387\n",
      "\n",
      "\n",
      "Epoch Number: 68\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204393\n",
      "\n",
      "\n",
      "Epoch Number: 69\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204393\n",
      "\n",
      "\n",
      "Epoch Number: 70\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204398\n",
      "\n",
      "\n",
      "Epoch Number: 71\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204396\n",
      "\n",
      "\n",
      "Epoch Number: 72\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204389\n",
      "\n",
      "\n",
      "Epoch Number: 73\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204397\n",
      "\n",
      "\n",
      "Epoch Number: 74\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 75\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204397\n",
      "\n",
      "\n",
      "Epoch Number: 76\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204398\n",
      "\n",
      "\n",
      "Epoch Number: 77\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204397\n",
      "\n",
      "\n",
      "Epoch Number: 78\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204389\n",
      "\n",
      "\n",
      "Epoch Number: 79\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204397\n",
      "\n",
      "\n",
      "Epoch Number: 80\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 81\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204396\n",
      "\n",
      "\n",
      "Epoch Number: 82\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 83\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 84\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 85\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204394\n",
      "\n",
      "\n",
      "Epoch Number: 86\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204396\n",
      "\n",
      "\n",
      "Epoch Number: 87\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204394\n",
      "\n",
      "\n",
      "Epoch Number: 88\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204394\n",
      "\n",
      "\n",
      "Epoch Number: 89\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 90\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204396\n",
      "\n",
      "\n",
      "Epoch Number: 91\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 92\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 94\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 95\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 96\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 97\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 98\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 99\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n",
      "Epoch Number: 100\n",
      "Current Training Loss: 0.00199248\n",
      "Current Validation Loss: 0.00204395\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#main _ train\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# use optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=.01,weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.steps, gamma=0.5)\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "val_best = 1\n",
    "# initialize graph\n",
    "for epoch in range(args.epochs):\n",
    "    print(\"Epoch Number: \" + str(epoch + 1))\n",
    "    \n",
    "    \n",
    "    # tracking \n",
    "    avg_trn_loss = AverageMeter()\n",
    "    avg_val_loss = AverageMeter()\n",
    "    \n",
    "    epoch_trn_loss = []\n",
    "    epoch_val_loss = []\n",
    "    \n",
    "    #bar = Bar('Training Graph Net', max=int(len(train_dataset.inputs)/args.batch_size))\n",
    "    end = time.time()\n",
    "    net.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.to(args.device)\n",
    "        targets = targets.to(args.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #print(inputs.shape)\n",
    "        predicted = net(g,inputs[0])\n",
    "        loss = criterion(predicted, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update tracking\n",
    "        np_loss = loss.detach().cpu().numpy()\n",
    "        avg_trn_loss.update(np_loss, 64)\n",
    "        epoch_trn_loss.append(np_loss)\n",
    "        #print(f\"Batch index {batch_idx} Out of {len(train_loader)}\")\n",
    "        #print(f\"Average Training Loss: {avg_trn_loss.avg}\")\n",
    "        \n",
    "    val_predictions = []\n",
    "    val_target = []\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for vbatch_idx, (vfeatures, vtargets) in enumerate(val_loader):\n",
    "            vfeatures = vfeatures.to(args.device)\n",
    "            vtarget = vtargets.to(args.device)\n",
    "            \n",
    "            vpreds = net(g,vfeatures[0])\n",
    "            vloss = criterion(vpreds, vtargets)\n",
    "            \n",
    "            # TODO: un-normalize the loss and convert to MAE for better interpretation\n",
    "            \n",
    "            # storage and tracking\n",
    "            np_vloss = vloss.detach().cpu().numpy()\n",
    "            np_vpreds = vpreds.detach().cpu().numpy()\n",
    "            np_vtarget = vtarget.detach().cpu().numpy()\n",
    "            avg_val_loss.update(np_vloss, args.batch_size)\n",
    "            epoch_val_loss.append(np_vloss)\n",
    "            val_predictions.append(np_vpreds)\n",
    "            val_target.append(np_vtarget)\n",
    "            \n",
    "        \n",
    "            \n",
    "    scheduler.step()\n",
    "    \n",
    "    train_loss.append(np.mean(epoch_trn_loss))\n",
    "    val_loss.append(np.mean(epoch_val_loss))\n",
    "    val_predictions = np.concatenate(val_predictions)\n",
    "    val_target = np.concatenate(val_target)\n",
    "    \n",
    "    # TODO: If validation imporves then save model \n",
    "    if val_loss[-1] < val_best:\n",
    "        val_best = val_loss[-1]\n",
    "        saveCheckpoint(net, filename = args.model_name)\n",
    "        \n",
    "    # show results\n",
    "    #print(val_target[0][0], val_predictions[0][0])\n",
    "    #print(val_target[0][1], val_predictions[0][1])\n",
    "    print(\"Current Training Loss: \" + str(round(train_loss[-1], 8)))\n",
    "    print(\"Current Validation Loss: \" + str(round(val_loss[-1], 8)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Train & Validation MSE Loss')\n",
    "plt.plot(train_loss, label = \"Training Loss\")\n",
    "plt.plot(val_loss, label = \"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
